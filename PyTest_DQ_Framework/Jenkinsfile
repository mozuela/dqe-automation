pipeline {
    agent any

    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }

        stage('Setup Environment') {
            steps {
                sh '''
                    echo "=== Setting up Python Virtual Environment ==="
                    python3 -m venv venv
                    . venv/bin/activate
                    pip install -r PyTest_DQ_Framework/requirements.txt
                    echo "Dependencies installed successfully"
                '''
            }
        }

        stage('Run DQE Tests') {
            steps {
                script {
                    withCredentials([
                        usernamePassword(
                            credentialsId: 'postgres-dqe',
                            usernameVariable: 'DB_USER',
                            passwordVariable: 'DB_PASSWORD'
                        )
                    ]) {
                        sh '''
                            echo "=== Running DQE Tests ==="
                            echo "Test Parameters:"
                            echo "- Database Host: host.docker.internal"
                            echo "- Database Port: 5434"
                            echo "- Database Name: mydatabase"
                            echo "- Database User: ${DB_USER}"
                            echo "- Test Directory: tests/dq_checks/parquet_files/"

                            . venv/bin/activate
                            cd PyTest_DQ_Framework
                            mkdir -p reports

                            # Run tests and capture output
                            echo "Executing pytest..."
                            python -m pytest tests/dq_checks/parquet_files/ -v \
                                --db_host=host.docker.internal \
                                --db_port=5434 \
                                --db_name=mydatabase \
                                --db_user=${DB_USER} \
                                --db_password=${DB_PASSWORD} \
                                --html=reports/test_report.html \
                                --self-contained-html \
                                --junitxml=reports/junit_results.xml 2>&1 | tee test_output.log || true

                            # Generate dynamic summary
                            echo ""
                            echo "=== TEST EXECUTION SUMMARY ==="

                            # Check if tests ran
                            if [ -f "test_output.log" ]; then
                                echo "Test execution log captured."

                                # Extract key information
                                TOTAL_TESTS=$(grep -E "collected [0-9]+ items" test_output.log | tail -1 | grep -oE "[0-9]+" || echo "0")
                                PASSED=$(grep -E "passed" test_output.log | grep -oE "[0-9]+" | head -1 || echo "0")
                                FAILED=$(grep -E "failed" test_output.log | grep -oE "[0-9]+" | head -1 || echo "0")
                                SKIPPED=$(grep -E "skipped" test_output.log | grep -oE "[0-9]+" | head -1 || echo "0")
                                ERRORS=$(grep -E "errors" test_output.log | grep -oE "[0-9]+" | head -1 || echo "0")

                                echo "Total Tests Collected: ${TOTAL_TESTS}"
                                echo "Tests Passed: ${PASSED}"
                                echo "Tests Failed: ${FAILED}"
                                echo "Tests Skipped: ${SKIPPED}"
                                echo "Tests with Errors: ${ERRORS}"

                                # Show test names and status
                                echo ""
                                echo "=== INDIVIDUAL TEST RESULTS ==="
                                grep -E "test_.* (PASSED|FAILED|ERROR|SKIPPED)" test_output.log | head -20 || echo "No detailed test results found in log"

                                # Show errors if any
                                if [ "${FAILED}" != "0" ] || [ "${ERRORS}" != "0" ]; then
                                    echo ""
                                    echo "=== FAILURES AND ERRORS DETECTED ==="
                                    grep -A 10 -B 2 "FAILURES\|ERRORS" test_output.log || echo "No failure details extracted"

                                    # Show first few lines of actual failures
                                    echo ""
                                    echo "First failure details:"
                                    grep -A 5 "FAILED\|ERROR" test_output.log | head -20 || echo "No failure details available"
                                fi
                            else
                                echo "WARNING: Test output log not found"
                            fi

                            # Check report generation
                            if [ -f "reports/test_report.html" ]; then
                                echo ""
                                echo "=== REPORT GENERATION ==="
                                echo "HTML Report: reports/test_report.html"
                                echo "JUnit Report: reports/junit_results.xml"
                                echo "Report filesize: $(du -h reports/test_report.html | cut -f1)"
                            else
                                echo "WARNING: HTML report was not generated"
                            fi

                            echo ""
                            echo "=== EXECUTION COMPLETED ==="
                        '''
                    }
                }
            }
        }

        stage('Archive Results') {
            steps {
                sh '''
                    echo "=== Archiving Test Results ==="
                    echo "Archiving reports and logs..."
                '''
                archiveArtifacts artifacts: 'PyTest_DQ_Framework/reports/*, PyTest_DQ_Framework/test_output.log', fingerprint: true
                junit 'PyTest_DQ_Framework/reports/junit_results.xml'
            }
        }
    }

    post {
        always {
            sh '''
                echo "=== PIPELINE EXECUTION SUMMARY ==="
                echo "Job Name: ${JOB_NAME}"
                echo "Build Number: ${BUILD_NUMBER}"
                echo "Build URL: ${BUILD_URL}"
                echo "Workspace: ${WORKSPACE}"
                echo ""
                echo "Artifacts Available:"
                echo "- HTML Test Report: ${BUILD_URL}artifact/PyTest_DQ_Framework/reports/test_report.html"
                echo "- JUnit Results: ${BUILD_URL}artifact/PyTest_DQ_Framework/reports/junit_results.xml"
                echo "- Console Log: ${BUILD_URL}artifact/PyTest_DQ_Framework/test_output.log"
            '''
        }
        success {
            echo 'Pipeline executed successfully. Check test results for individual test status.'
        }
        failure {
            echo 'Pipeline execution encountered issues. Check console output and test reports for details.'
        }
    }
}